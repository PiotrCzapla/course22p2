{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp mps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set env variables to avoid warnings during multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "import torch, os\n",
    "import torch.backends.mps # for pyright\n",
    "import fastcore.all as fc\n",
    "# [W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel \n",
    "# work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
    "# Alternative if we won't find a way to use mutliprocessing with MPS:\n",
    "if torch.backends.mps.is_available():\n",
    "    if (k:='OMP_NUM_THREADS') not in os.environ: os.environ[k]='1'\n",
    "    if (k:='PYTORCH_ENABLE_MPS_FALLBACK') not in os.environ: os.environ[k]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from miniai.init import init_weights as orig_init_weights\n",
    "from miniai.activations import set_seed\n",
    "from miniai.learner import Callback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPS randn/normal don't use pytorch seeds\n",
    "\n",
    "Initially randn was always returning the same 'random' vector on mps, this changed with [patch](https://github.com/pytorch/pytorch/pull/78010/commits) but it does not use seed set with troch.manual_seed()\n",
    "\n",
    "So on mps we move the layers to cpu before init and then back to mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
      "         0.4617,  0.2674])\n",
      "tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
      "         0.4617,  0.2674])\n",
      "tensor([ 3.7750,  0.5150,  0.4238, -1.0694, -2.4454,  1.1967, -1.9430,  0.3254,\n",
      "        -0.3740, -0.3755], device='mps:0')\n",
      "tensor([-2.2156, -0.9671,  0.2496,  0.7735,  0.9785,  0.7212,  2.0625,  2.2164,\n",
      "        -2.3274,  0.0332], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/miniai/lib/python3.10/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "set_seed(42); print(torch.randn(10))\n",
    "set_seed(42); print(torch.randn(10))\n",
    "if torch.backends.mps.is_available():\n",
    "    set_seed(42); print(torch.randn(10, device='mps'))\n",
    "    set_seed(42); print(torch.randn(10, device='mps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaky\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaky\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleaky\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Workspace/fastai/part2/course22p2/miniai/init.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "??init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0626, device='mps:0', grad_fn=<MaxBackward1>) seed 42\n",
      "tensor(0.8696, device='mps:0', grad_fn=<MaxBackward1>) seed 42\n"
     ]
    }
   ],
   "source": [
    "c = torch.nn.Conv1d(10,10, 2)\n",
    "c.to('mps') \n",
    "set_seed(42)\n",
    "orig_init_weights(c)\n",
    "print(c.weight.max(), 'seed 42')\n",
    "set_seed(42)\n",
    "orig_init_weights(c)\n",
    "print(c.weight.max(), 'seed 42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_weights(m, *args, **kwargs):\n",
    "    devs = [p.device for p in m.parameters()]\n",
    "    try:\n",
    "        m.to('cpu')\n",
    "        return orig_init_weights(m, *args, **kwargs)\n",
    "    finally:\n",
    "        for p,d in zip(m.parameters(), devs): m.to(d)\n",
    "\n",
    "# This if cannot be in front of init_weights as then it nbdev won't put it to __all__\n",
    "if not torch.backends.mps.is_available(): init_weights = orig_init_weights # type: ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7014, device='mps:0', grad_fn=<MaxBackward1>) seed 42\n",
      "tensor(0.7014, device='mps:0', grad_fn=<MaxBackward1>) seed 42\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "init_weights(c)\n",
    "print(c.weight.max(), 'seed 42')\n",
    "set_seed(42)\n",
    "init_weights(c)\n",
    "print(c.weight.max(), 'seed 42')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reseed CB\n",
    "This callback facilitate using different seeds while still keeping the training reproducable by reporting the seed on each use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ReseedCB(Callback):\n",
    "    order = 0\n",
    "    def __init__(self): self.gen, self.new_seed = torch.Generator(), None\n",
    "    def before_fit(self, learn): \n",
    "        self.set_seed(self.new_seed)\n",
    "        print('Using seed', self.new_seed)\n",
    "    def set_seed(self, seed=None): \n",
    "        if seed is None: \n",
    "            self.new_seed = torch.randint(2**31, [1], generator=self.gen).item()\n",
    "            print(f\"New seed: {self.new_seed}\")\n",
    "        else:\n",
    "            self.new_seed = seed\n",
    "        set_seed(self.new_seed)\n",
    "        return self.new_seed\n",
    "    def previous(self): self.set_seed(self.new_seed)\n",
    "    def new(self): self.set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseed=ReseedCB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed is set twice, on pervious|new|set_seed and before every seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New seed: 205811062\n",
      "Using seed 205811062\n",
      "tensor([-0.5644, -1.8079,  0.5900,  0.6734,  0.0040, -0.6066, -0.3101,  0.8848,\n",
      "         0.0541,  0.3965])\n",
      "Using seed 205811062\n",
      "tensor([-0.5644, -1.8079,  0.5900,  0.6734,  0.0040, -0.6066, -0.3101,  0.8848,\n",
      "         0.0541,  0.3965])\n"
     ]
    }
   ],
   "source": [
    "reseed.before_fit(None)\n",
    "print(torch.randn(10))\n",
    "reseed.before_fit(None)\n",
    "print(torch.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5644, -1.8079,  0.5900,  0.6734,  0.0040, -0.6066, -0.3101,  0.8848,\n",
      "         0.0541,  0.3965])\n",
      "Using seed 205811062\n",
      "tensor([-0.5644, -1.8079,  0.5900,  0.6734,  0.0040, -0.6066, -0.3101,  0.8848,\n",
      "         0.0541,  0.3965])\n"
     ]
    }
   ],
   "source": [
    "reseed.previous()\n",
    "print(torch.randn(10)) # useful during init\n",
    "reseed.before_fit(None)\n",
    "print(torch.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
      "         0.4617,  0.2674])\n",
      "Using seed 42\n",
      "tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
      "         0.4617,  0.2674])\n"
     ]
    }
   ],
   "source": [
    "reseed.set_seed(42)\n",
    "print(torch.randn(10))\n",
    "reseed.before_fit(None)\n",
    "print(torch.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New seed: 1155489284\n",
      "tensor([ 0.1857,  0.5785,  0.1219, -0.4333, -0.8358, -0.3888, -1.5829, -0.6018,\n",
      "         0.2697,  0.2101])\n",
      "Using seed 1155489284\n",
      "tensor([ 0.1857,  0.5785,  0.1219, -0.4333, -0.8358, -0.3888, -1.5829, -0.6018,\n",
      "         0.2697,  0.2101])\n"
     ]
    }
   ],
   "source": [
    "reseed.new()\n",
    "print(torch.randn(10))\n",
    "reseed.before_fit(None)\n",
    "print(torch.randn(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniai",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
