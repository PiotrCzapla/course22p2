{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by @christopherthomas’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/fastai/course22p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd course22p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,random\n",
    "import fastcore.all as fc,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "from collections.abc import Mapping\n",
    "from pathlib import Path\n",
    "from operator import attrgetter,itemgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "from torch import tensor,nn,optim\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.conv import *\n",
    "from miniai.learner import *\n",
    "from miniai.activations import *\n",
    "from miniai.init import *\n",
    "from miniai.sgd import *\n",
    "from miniai.resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close\n",
    "from torch import distributions\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "if fc.defaults.cpus>8: fc.defaults.cpus=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.1\n",
    "dist = distributions.binomial.Binomial(probs=1-p)\n",
    "dist.sample((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p=0.1):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training: return x\n",
    "        dist = distributions.binomial.Binomial(tensor(1.0).to(x.device), probs=1-self.p)\n",
    "        return x * dist.sample(x.size()) * 1/(1-self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTD_CB(Callback):\n",
    "    def before_epoch(self, learn):\n",
    "        learn.model.apply(lambda m: m.train() if isinstance(m, (nn.Dropout,nn.Dropout2d)) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  #(uncomment if needed,but you likely already have it)\n",
    "\n",
    "#Mish - \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\"\n",
    "#https://arxiv.org/abs/1908.08681v1\n",
    "#implemented for PyTorch / FastAI by lessw2020 \n",
    "#github: https://github.com/lessw2020/mish\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #inlining this saves 1 second per epoch (V100 GPU) vs having a temp x and then returning x(!)\n",
    "        return x *( torch.tanh(F.softplus(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "class TopLossesCallback(Callback):\n",
    "  epoch_preds = []\n",
    "  epoch_targets = []\n",
    "  \n",
    "  @torch.no_grad()\n",
    "  def _calculate_top_losses(self):\n",
    "    preds = torch.cat(self.epoch_preds, dim=0)\n",
    "    targets = torch.cat(self.epoch_targets, dim=0)\n",
    "    losses = F.cross_entropy(preds, targets, reduce=False)\n",
    "    return torch.topk(losses, preds.shape[0]).indices\n",
    "\n",
    "  def after_batch(self, learn):\n",
    "    if not learn.model.training:\n",
    "      return\n",
    "    self.epoch_preds.append(learn.preds)\n",
    "    self.epoch_targets.append(learn.batch[1])\n",
    "\n",
    "  def before_epoch(self, learn):\n",
    "    self.epoch_preds = []\n",
    "    self.epoch_targets = []\n",
    "\n",
    "  def after_epoch(self, learn):\n",
    "    if not learn.model.training:\n",
    "      return\n",
    "    learn.dls.train.sampler.top_losses = self._calculate_top_losses()\n",
    "\n",
    "# tweaked from tommyc's version\n",
    "# Before certain epoch drop a % of the training dataset with the lowest losses.\n",
    "# Replace them with the the same % of the training dataset with the highest losses.\n",
    "# This gives the model two opportunities to train on the most challenging images.\n",
    "class CustomTrainingSampler(WeightedRandomSampler):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    WeightedRandomSampler.__init__(self, *args, **kwargs)\n",
    "    self.data_indexes_for_epoch = []\n",
    "    self.top_losses = []\n",
    "    self.epoch = -1\n",
    "    self.n = {\n",
    "        0: 0,\n",
    "        1: 0.2,\n",
    "        2: 0.4,\n",
    "        3: 0.2,\n",
    "        4: 0\n",
    "    }\n",
    "\n",
    "  def __iter__(self) -> Iterator[int]:\n",
    "      self.epoch += 1\n",
    "      rand_tensor = torch.randperm(self.num_samples, generator=self.generator).tolist()\n",
    "      n = int(self.n[self.epoch] * self.num_samples)\n",
    "\n",
    "      if n != 0:\n",
    "        # TODO: Cleanup the code below\n",
    "        inverted_losses_for_epochs = torch.flip(torch.tensor(self.top_losses.clone().detach()[:n]), dims=(0,)).cpu()\n",
    "        self.data_indexes_for_epoch = torch.tensor(self.data_indexes_for_epoch).cpu()\n",
    "        self.data_indexes_for_epoch[self.top_losses[-n:].cpu()] = self.data_indexes_for_epoch[inverted_losses_for_epochs]\n",
    "        self.data_indexes_for_epoch = self.data_indexes_for_epoch[rand_tensor]\n",
    "        self.data_indexes_for_epoch = self.data_indexes_for_epoch.tolist()\n",
    "      else:\n",
    "        self.data_indexes_for_epoch = rand_tensor\n",
    "\n",
    "      yield from self.data_indexes_for_epoch\n",
    "\n",
    "\n",
    "class CustomDataLoader:\n",
    "    def __init__(self, *dls): \n",
    "      self.train,self.valid = dls[:2]\n",
    "\n",
    "    def get_sampler(num_samples, mode=\"train\"):\n",
    "      if mode != \"train\":\n",
    "        return None\n",
    "      return CustomTrainingSampler(weights=[1 for _ in range(num_samples)], num_samples=num_samples)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dd(cls, dd, batch_size, as_tuple=True, **kwargs):\n",
    "      return cls(*[DataLoader(ds, batch_size, sampler=cls.get_sampler(len(ds), mode), collate_fn=collate_dict(ds), **kwargs) for mode, ds in dd.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a023710d16a54b5e919de04e1bf7a8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xl,yl = 'image','label'\n",
    "name = \"fashion_mnist\"\n",
    "bs = 256\n",
    "xmean,xstd = 0.28, 0.35\n",
    "\n",
    "@inplace\n",
    "def transformi(b): b[xl] = [(TF.to_tensor(o)-xmean)/xstd for o in b[xl]]\n",
    "\n",
    "dsd = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniai.mps import cache_dataset_as_dict\n",
    "\n",
    "\n",
    "\n",
    "tds = cache_dataset_as_dict(dsd.with_transform(transformi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniai.utils import SpeedStatsCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "lr,epochs = 6e-2,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model7(act=nn.ReLU, nfs=(16,32,64,128,256,512), norm=nn.BatchNorm2d):\n",
    "    layers = [ResBlock(1, 16, ks=5, stride=1, act=act, norm=norm)]\n",
    "    layers += [ResBlock(nfs[i], nfs[i+1], act=act, norm=norm, stride=2) for i in range(len(nfs)-1)]\n",
    "    layers += [nn.Dropout2d(0.2), nn.Flatten(), nn.Linear(nfs[-1], 10, bias=False), nn.BatchNorm1d(10)]\n",
    "    return nn.Sequential(*layers).to(def_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfm_batch(b, tfm_x=fc.noop, tfm_y = fc.noop): return tfm_x(b[0]),tfm_y(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = nn.Sequential(transforms.RandomCrop(28, padding=1),\n",
    "                     transforms.RandomHorizontalFlip())\n",
    "augcb = BatchTransformCB(partial(tfm_batch, tfm_x=tfms), on_val=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapturePreds(Callback):\n",
    "    def before_fit(self, learn): self.all_preds,self.all_targs = [],[]\n",
    "    def after_batch(self, learn):\n",
    "        self.all_preds.append(to_cpu(learn.preds))\n",
    "        self.all_targs.append(to_cpu(learn.batch[1]))\n",
    "    def after_fit(self, learn): self.all_preds,self.all_targs = torch.cat(self.all_preds),torch.cat(self.all_targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fc.patch\n",
    "def capture_preds(self: Learner, cbs=None):\n",
    "    cp = CapturePreds()\n",
    "    self.fit(1, train=False, cbs=[cp]+fc.L(cbs))\n",
    "    return cp.all_preds,cp.all_targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweaked from rohitgeo's version\n",
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())\n",
    "astats = ActivationStats(fc.risinstance(Mish))\n",
    "cbs = [SpeedStatsCB(), DeviceCB(), metrics, TopLossesCallback(), ProgressCB(plot=True), astats]\n",
    "\n",
    "# #0.0003 from https://github.com/digantamisra98/Mish/issues/37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xdls = CustomDataLoader.from_dd(tds, bs, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/5 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/30 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act_gr = nn.ReLU\n",
    "iw = partial(init_weights, leaky=0.0003)\n",
    "\n",
    "set_seed(42)\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 *m\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "model = get_model7(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_gr = partial(GeneralRelu, leak=0.1, sub=0.4)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "#iw = partial(init_weights, leaky=0.0003)\n",
    "\n",
    "set_seed(42)\n",
    "epochs = 1\n",
    "m = 8\n",
    "lr = 1e-2 *m\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "model = get_model7(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_gr = nn.Hardswish\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "#iw = partial(init_weights, leaky=0.0003)\n",
    "\n",
    "set_seed(42)\n",
    "epochs = 1\n",
    "m = 8\n",
    "lr = 1e-2 *m\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "model = get_model7(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_gr = nn.Hardswish\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "#iw = partial(init_weights, leaky=0.0003)\n",
    "\n",
    "set_seed(42)\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 *m\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "model = get_model7(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniai.init_lsuv import LSUVInit\n",
    "\n",
    "act_gr = nn.Hardswish\n",
    "iw = partial(init_weights, leaky=0.000)\n",
    "#iw = partial(init_weights, leaky=0.0003)\n",
    "\n",
    "set_seed(42)\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 *m\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "xtra += [LSUVInit(skip_last=1)]\n",
    "model = get_model7(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSUVInit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_gr = partial(GeneralRelu, leak=0.1, sub=0.4)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "#iw = partial(init_weights, leaky=0.0003)\n",
    "\n",
    "set_seed(42)\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 *m\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "model = get_model7(act_gr, norm=nn.BatchNorm2d).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, \n",
    "                     opt_func=partial(optim.AdamW,  ))\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "set_seed(42)\n",
    "epochs = 5\n",
    "lr = 1e-2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "model = timm.create_model('resnet18d', in_chans=1, num_classes=10)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = partial(init_weights, leaky=0.0)\n",
    "\n",
    "set_seed(42)\n",
    "epochs = 5\n",
    "lr = 1e-2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "model = timm.create_model('resnet18d', in_chans=1, num_classes=10).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_gr(inplace=None): return GeneralRelu(leak=0.1, sub=0.4)\n",
    "set_seed(42)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "\n",
    "model = timm.create_model('resnet18d', in_chans=1, num_classes=10, act_layer=act_gr).apply(iw)\n",
    "\n",
    "epochs = 5\n",
    "lr = 1e-2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_gr(inplace=None): return GeneralRelu(leak=0.1, sub=0.4)\n",
    "set_seed(42)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "\n",
    "model = timm.create_model('resnet18d', in_chans=1, num_classes=10, act_layer=act_gr).apply(iw)\n",
    "\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 * m / 4\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_gr(inplace=None): return GeneralRelu(leak=0.1, sub=0.4)\n",
    "set_seed(42)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "\n",
    "model = timm.create_model('resnet34d', in_chans=1, num_classes=10, act_layer=act_gr).apply(iw)\n",
    "\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 * m / 4\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_gr(inplace=None): return GeneralRelu(leak=0.1, sub=0.4)\n",
    "set_seed(42)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "\n",
    "model = timm.create_model('resnet50d', in_chans=1, num_classes=10, act_layer=act_gr).apply(iw)\n",
    "\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 * m / 8\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficient net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('effici*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def act_gr(inplace=None): return GeneralRelu(leak=0.1, sub=0.4)\n",
    "set_seed(42)\n",
    "# iw = partial(init_weights, leaky=0.1)\n",
    "\n",
    "model = timm.create_model('efficientnet_lite0', in_chans=1, num_classes=10, )#.apply(init_weights)\n",
    "\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 * m /2\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def act_gr(inplace=None): return GeneralRelu(leak=0.1, sub=0.4)\n",
    "set_seed(42)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "\n",
    "model = timm.create_model('efficientnet_lite0', in_chans=1, num_classes=10, act_layer=act_gr \n",
    "                         ).apply(iw)\n",
    "\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 * m /4\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convnext_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('convnext*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = timm.create_model('convnext_pico', in_chans=1, num_classes=10, output_stride=16)\n",
    "\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 * m / 8\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "xtra += [LSUVInit(skip_last=1)]\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = timm.create_model('convnext_pico', in_chans=1, num_classes=10, output_stride=16).apply(iw)\n",
    "\n",
    "epochs = 5\n",
    "m = 8\n",
    "lr = 1e-2 * m / 8\n",
    "dls = DataLoaders.from_dd(tds, bs*m, num_workers=0)\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "#xtra += [LSUVInit(skip_last=1)]\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = timm.create_model('convnext_nano', in_chans=1, num_classes=10, output_stride=16)\n",
    "\n",
    "epochs = 5\n",
    "lr = 1e-2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in str(model).split('\\n') if 'stride' in i and not 'stride=(1, 1)' in i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = timm.create_model('convnext_base', in_chans=1, num_classes=10, output_stride=16)\n",
    "\n",
    "epochs = 5\n",
    "lr = 1e-2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('levit*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_gr(inplace=None): return GeneralRelu(leak=0.1, sub=0.4)\n",
    "set_seed(42)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "\n",
    "model = timm.create_model('levit_128', in_chans=1, num_classes=10)\n",
    "\n",
    "epochs = 5\n",
    "lr = 1e-2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__init__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_gr(inplace=None): return GeneralRelu(leak=0.1, sub=0.4)\n",
    "set_seed(42)\n",
    "iw = partial(init_weights, leaky=0.1)\n",
    "\n",
    "model = timm.create_model('levit', in_chans=1, num_classes=10)\n",
    "\n",
    "epochs = 5\n",
    "lr = 1e-2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__init__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtra += [LSUVInit(skip_last=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = partial(init_weights, leaky=0.0)\n",
    "\n",
    "set_seed(42)\n",
    "epochs = 5\n",
    "lr = 1e-2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched), augcb]\n",
    "model = timm.create_model('resnet18d', in_chans=1, num_classes=10).apply(iw)\n",
    "learn = TrainLearner(model, dls, F.cross_entropy, lr=lr, cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap1, at = learn.capture_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttacb = BatchTransformCB(partial(tfm_batch, tfm_x=TF.hflip), on_val=True)\n",
    "ap2, at = learn.capture_preds(cbs=[ttacb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = torch.stack([ap1,ap2]).mean(0).argmax(1)\n",
    "round((ap==at).float().mean().item(), 3)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ed42b2e75d84554bc8f9717f2d3345e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16fa6046316b4c6b906c18bb28569be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cdff99f023f4675b4bbfbd496c05916": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1da56c769b934fd6b95236489650c5e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ed42b2e75d84554bc8f9717f2d3345e",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6679fc3c87aa478eb08dbc27a8338920",
      "value": 2
     }
    },
    "259fc738f162455aa67d57181c66b880": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cdff99f023f4675b4bbfbd496c05916",
      "placeholder": "​",
      "style": "IPY_MODEL_16fa6046316b4c6b906c18bb28569be3",
      "value": "100%"
     }
    },
    "51720494a36d4f5e80a2ab96a85c7fbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6679fc3c87aa478eb08dbc27a8338920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6f775e9ea905449fb3139192d570bf7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81116b72146245a58dab9980b4026971": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51720494a36d4f5e80a2ab96a85c7fbe",
      "placeholder": "​",
      "style": "IPY_MODEL_6f775e9ea905449fb3139192d570bf7e",
      "value": " 2/2 [00:00&lt;00:00, 68.16it/s]"
     }
    },
    "c11057260c8642569fa83f8f3dc37836": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4ebd5dafc6e40f2b6f20eb8a446c6cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_259fc738f162455aa67d57181c66b880",
       "IPY_MODEL_1da56c769b934fd6b95236489650c5e4",
       "IPY_MODEL_81116b72146245a58dab9980b4026971"
      ],
      "layout": "IPY_MODEL_c11057260c8642569fa83f8f3dc37836"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
