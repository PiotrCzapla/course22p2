{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from pathlib import Path\n",
    "from operator import attrgetter,itemgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "from torch import tensor,nn,optim\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.conv import *\n",
    "from miniai.learner import *\n",
    "from miniai.activations import *\n",
    "from miniai.mps import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reseed CB\n",
    "This callback facilitate using different seeds while still keeping the training reproducable by reporting the seed on each use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RNGSeedCB(Callback):\n",
    "    order = 0\n",
    "    def __init__(self, verbose=True): \n",
    "        self.gen, self.new_seed, self.log = torch.Generator(), None, print if verbose else fc.noop\n",
    "    def before_fit(self, learn): \n",
    "        self.set_seed(self.new_seed)\n",
    "        \n",
    "    def set_seed(self, seed=None): \n",
    "        if seed is None: \n",
    "            self.new_seed = torch.randint(2**31, [1], generator=self.gen).item()\n",
    "        else:\n",
    "            self.new_seed = seed  \n",
    "        self.log(\"Reseed:\",self.new_seed)\n",
    "        set_seed(self.new_seed)\n",
    "        return self.new_seed\n",
    "    def new(self): self.set_seed()\n",
    "    def previous(self): self.set_seed(self.new_seed)\n",
    "    \n",
    "ReseedCB = RNGSeedCB\n",
    "RNG = RNGSeedCB()\n",
    "rng_seed = RNG # old name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed is set twice, on pervious|new|set_seed and before every seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseed: 205811062\n",
      "tensor([-0.5644, -1.8079,  0.5900,  0.6734,  0.0040, -0.6066, -0.3101,  0.8848,\n",
      "         0.0541,  0.3965])\n",
      "Reseed: 205811062\n",
      "tensor([-0.5644, -1.8079,  0.5900,  0.6734,  0.0040, -0.6066, -0.3101,  0.8848,\n",
      "         0.0541,  0.3965])\n"
     ]
    }
   ],
   "source": [
    "RNG.before_fit(None)\n",
    "print(torch.randn(10))\n",
    "RNG.before_fit(None)\n",
    "print(torch.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseed: 205811062\n",
      "tensor([-0.5644, -1.8079,  0.5900,  0.6734,  0.0040, -0.6066, -0.3101,  0.8848,\n",
      "         0.0541,  0.3965])\n",
      "Reseed: 205811062\n",
      "tensor([-0.5644, -1.8079,  0.5900,  0.6734,  0.0040, -0.6066, -0.3101,  0.8848,\n",
      "         0.0541,  0.3965])\n"
     ]
    }
   ],
   "source": [
    "RNG.previous()\n",
    "print(torch.randn(10)) # useful during init\n",
    "RNG.before_fit(None)\n",
    "print(torch.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseed: 42\n",
      "tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
      "         0.4617,  0.2674])\n",
      "Reseed: 42\n",
      "tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
      "         0.4617,  0.2674])\n"
     ]
    }
   ],
   "source": [
    "RNG.set_seed(42)\n",
    "print(torch.randn(10))\n",
    "RNG.before_fit(None)\n",
    "print(torch.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseed: 1155489284\n",
      "tensor([ 0.1857,  0.5785,  0.1219, -0.4333, -0.8358, -0.3888, -1.5829, -0.6018,\n",
      "         0.2697,  0.2101])\n",
      "Reseed: 1155489284\n",
      "tensor([ 0.1857,  0.5785,  0.1219, -0.4333, -0.8358, -0.3888, -1.5829, -0.6018,\n",
      "         0.2697,  0.2101])\n"
     ]
    }
   ],
   "source": [
    "RNG.new()\n",
    "print(torch.randn(10))\n",
    "RNG.before_fit(None)\n",
    "print(torch.randn(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed of Training\n",
    "\n",
    "Unfortunately the multiprocessing is a bit slower on MPS as the main process has to share the number of OMP Threads (the value cannot be changed after fork). So to avoid warnings it is set to 1. Which makes the dataloader a bit slower.  To workaround this i've added cache_dataset_as_dict\n",
    "\n",
    "It improves the performance 4x for large batch sizes from:\n",
    "- 16 sec per fit(5)\n",
    "\n",
    "to:\n",
    "\n",
    "- 5 sec initial loading time\n",
    "- 3.6 sec per fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from pathlib import Path\n",
    "from operator import attrgetter,itemgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "from torch import tensor,nn,optim\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from datasets import load_dataset,load_dataset_builder\n",
    "\n",
    "from miniai.datasets import *\n",
    "from miniai.conv import *\n",
    "from miniai.learner import *\n",
    "from miniai.activations import *\n",
    "from miniai.init import get_model, init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lazy metrics and progress bar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torcheval.metrics import Metric, Mean\n",
    "    me = Mean(device=def_device)\n",
    "except TypeError as e: # on mps device\n",
    "    assert \"MPS framework doesn't support float64\" in str(e)\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torcheval.metrics import Metric, Mean\n",
    "class LazyMean(Mean):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.buffer = []\n",
    "        \n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.buffer = []\n",
    "    \n",
    "    def to(self, device): pass # ignore we compute on cpu\n",
    "\n",
    "    def update(self, val, weight=tensor(1.0)): self.buffer.append((val.detach(), tensor(weight).detach().float()))\n",
    "\n",
    "    def compute(self):\n",
    "        for val,w in self.buffer: super().update(val.to('cpu'), weight=w.to('cpu'))\n",
    "        self.buffer = []    \n",
    "        return super().compute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from copy import copy\n",
    "from miniai.learner import Mean, master_bar, progress_bar\n",
    "class LazyMetricsCB(Callback):\n",
    "    order = MetricsCB.order\n",
    "    def __init__(self, *ms, device=def_device, **metrics):\n",
    "        for o in ms: metrics[type(o).__name__] = o\n",
    "        self.metrics = metrics\n",
    "        self.all_metrics = copy(metrics)\n",
    "        self.all_metrics['loss'] = self.loss = LazyMean() if torch.backends.mps.is_available() else Mean()\n",
    "        self.device = def_device\n",
    "\n",
    "    def _log(self, d): print(d)\n",
    "    def before_fit(self, learn): \n",
    "        learn.metrics = self \n",
    "        self.device = [*(cb.device for cb in learn.cbs if isinstance(cb, DeviceCB)), self.device][0]\n",
    "                \n",
    "    def before_epoch(self, learn): \n",
    "        for o in self.all_metrics.values(): \n",
    "            o.reset()\n",
    "            o.to(self.device)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def after_epoch(self, learn):\n",
    "        log = {k:f'{to_cpu(v.compute()):.3f}' for k,v in self.all_metrics.items()}\n",
    "        log['epoch'] = learn.epoch\n",
    "        log['train'] = 'train' if learn.model.training else 'eval'\n",
    "        self._log(log)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = learn.batch\n",
    "        for m in self.metrics.values(): m.update(learn.preds, y)\n",
    "        self.loss.update(learn.loss, weight=len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LazyProgressCB(Callback):\n",
    "    order = MetricsCB.order+1\n",
    "    def __init__(self, plot=False): \n",
    "        self.plot = plot\n",
    "        self.count = 0\n",
    "    def before_fit(self, learn):\n",
    "        learn.epochs = self.mbar = master_bar(learn.epochs)\n",
    "        self.first = True\n",
    "        if hasattr(learn, 'metrics'): learn.metrics._log = self._log\n",
    "        self.dev_losses = []\n",
    "        self.losses = []\n",
    "\n",
    "    def _log(self, d):\n",
    "        if self.first:\n",
    "            self.mbar.write(list(d), table=True)\n",
    "            self.first = False\n",
    "        self.mbar.write(list(d.values()), table=True)\n",
    "        if self.plot:\n",
    "            for l in self.dev_losses: self.losses.append(to_cpu(l))\n",
    "            self.dev_losses=[]\n",
    "            #print(self.losses[:10])\n",
    "            self.mbar.update_graph([[fc.L.range(self.losses), self.losses]])\n",
    "        \n",
    "    def before_epoch(self, learn): learn.dl = progress_bar(learn.dl, leave=False, parent=self.mbar)\n",
    "    def after_batch(self, learn):\n",
    "        #learn.dl.comment = f'{learn.loss:.3f}' # not sure how it is being used\n",
    "        if self.plot and hasattr(learn, 'metrics') and learn.training:\n",
    "            self.dev_losses.append(learn.loss.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "\n",
    "def _format_stats(stats):\n",
    "    return f\"{stats.mean():.2f} Â± {stats.std():.2f}\"\n",
    "\n",
    "class TimeItCB(Callback):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def tick(self): return time.time()\n",
    "         \n",
    "    def reset(self):\n",
    "        self.start = self.tick()\n",
    "        self.setup = None\n",
    "        self.batches = {True:[], False:[]}\n",
    "        self.epochs = {True:[], False:[]}\n",
    "        self.samples = {True:[], False:[]}\n",
    "    def before_fit(self, learn):\n",
    "        self.reset()\n",
    "        \n",
    "    def before_batch(self, learn):\n",
    "        if self.setup is None: self.setup = self.tick() - self.start\n",
    "        self.batches[learn.training].append(self.tick())\n",
    "    \n",
    "    def after_batch(self, learn):\n",
    "        self.batches[learn.training][-1] = self.tick() - self.batches[learn.training][-1]\n",
    "        self.samples[learn.training].append(learn.batch[0].shape[0])\n",
    "    \n",
    "    def before_epoch(self, learn):\n",
    "        self.epochs[learn.training].append(self.tick())\n",
    "    \n",
    "    def after_epoch(self, learn):\n",
    "        self.epochs[learn.training][-1] = self.tick() - self.epochs[learn.training][-1]\n",
    "    \n",
    "    def after_fit(self, learn):\n",
    "        self.total = self.tick() - self.start\n",
    "        self.setup = self.setup / self.total\n",
    "        self.batches = {k:np.array(v) for k,v in self.batches.items()}\n",
    "        self.epochs = {k:np.array(v) for k,v in self.epochs.items()}\n",
    "        self.samples = {k:np.array(v) for k,v in self.samples.items()}\n",
    "        self.print_stats()\n",
    "    \n",
    "    def print_stats(self): \n",
    "        print(f\"Fit {len(self.epochs[True])} in: {self.total:.2f}s, setup: {self.setup:.2f}s, {_format_stats(self.epochs[True])}s per epoch, {_format_stats(self.batches[True])}s per batch\")\n",
    "        #print(f\" samples/sec: {self.samples[True].sum() / self.total:.2f}s, time_in_val: {self.epochs[False].sum() / self.total:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# if spawn is not possible, we can cache the entire dataset in memory after transformations\n",
    "def _with_features(ds):\n",
    "    setattr((l:=fc.L(ds)), 'features', ds.features)\n",
    "    return l \n",
    "def cache_dataset_as_dict(dd): return {dsn: _with_features(ds) for dsn,ds in dd.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_cbs = [DeviceCB(), LazyMetricsCB(accuracy=MulticlassAccuracy()), LazyProgressCB(plot=True), TimeItCB()]\n",
    "eager_cbs = [DeviceCB(), LazyMetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(plot=True), TimeItCB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "xmean, xstd = 0.28, 0.35\n",
    "name = \"fashion_mnist\"\n",
    "def to_tensor_tfm(b, mean, std, xl='image'): \n",
    "    b[xl] = [(TF.to_tensor(o)-mean)/std for o in b[xl]]\n",
    "    return b\n",
    "\n",
    "dsd = load_dataset(name)\n",
    "tds = dsd.with_transform(partial(to_tensor_tfm, mean=xmean, std=xstd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_speed(cbs, dls):\n",
    "    set_seed(42)\n",
    "    learn = TrainLearner(get_model().to('cpu').apply(init_weights), dls, \n",
    "                         F.cross_entropy, lr=1e-2, cbs=cbs, opt_func=optim.AdamW)\n",
    "    learn.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "test_speed(eager_cbs, dls=DataLoaders.from_dd(tds, bs, num_workers=4, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_speed(lazy_cbs, dls=DataLoaders.from_dd(tds, bs, num_workers=4, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "tds.cached = cache_dataset_as_dict(tds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_speed(eager_cbs, dls=DataLoaders.from_dd(tds.cached, bs, num_workers=0, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_speed(lazy_cbs, dls=DataLoaders.from_dd(tds.cached, bs, num_workers=0, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tds.cached['train']), bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
