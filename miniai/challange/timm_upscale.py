# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/contest/other_arch/resnet18d_old_first_attempt.ipynb.

# %% auto 0
__all__ = ['Upscale', 'timm_model', 'model9_ct', 'model_base_resnet', 'OneCycleLRWithPlateau', 'MixUpFP16CB', 'tfm_batch',
           'get_augcb']

# %% ../../nbs/contest/other_arch/resnet18d_old_first_attempt.ipynb 2
import pickle,gzip,math,os,time,shutil,torch,random
import fastcore.all as fc,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt
from collections.abc import Mapping
from pathlib import Path
from operator import attrgetter,itemgetter
from functools import partial
from copy import copy
from contextlib import contextmanager

import torchvision.transforms.functional as TF,torch.nn.functional as F
from torchvision import transforms
from torch import tensor,nn,optim
from torch.utils.data import DataLoader,default_collate
from torch.nn import init
from torch.optim import lr_scheduler
from torcheval.metrics import MulticlassAccuracy
from datasets import load_dataset,load_dataset_builder

from ..datasets import *
from ..conv import *
from ..learner import *
from ..activations import *
from ..init import *
from ..sgd import *
from ..resnet import *
from ..augment import *
from .ct94ep5 import *
from ..utils import *
from ..accel import *
import timm

# %% ../../nbs/contest/other_arch/resnet18d_old_first_attempt.ipynb 9
class Upscale:
    def __init__(self, sz, align=True, const=0): fc.store_attr() 
    def _sz(self, n): return round(self.sz*n / 32)*32 if self.align else self.sz*n
    def antialiased(self, n): 
        return transforms.Resize(self._sz(n), transforms.InterpolationMode.BILINEAR, antialias=True)
    def bilinear(self, n): 
        return transforms.Resize(self._sz(n), transforms.InterpolationMode.BILINEAR, antialias=False)
    def nearest(self, n): 
        return transforms.Resize(self._sz(n), transforms.InterpolationMode.NEAREST)
    def pad(self, n): 
        return transforms.Pad((self._sz(n)-self.sz)//2, padding_mode='constant', fill=self.const)

# %% ../../nbs/contest/other_arch/resnet18d_old_first_attempt.ipynb 19
def timm_model(name, resize=nn.Identity(), **kw):
    RNG.previous()
    props = dict(in_chans=1, num_classes=10, pretrained=False)
    props.update(kw)
    model = nn.Sequential( 
        resize,
        timm.create_model(name, **props)
    )
    return dict(model=model)

# %% ../../nbs/contest/other_arch/resnet18d_old_first_attempt.ipynb 20
# Cristopher Thomas 94.9% 5epochs
def model9_ct(**kw):
    from miniai.challange.ct94ep5 import get_model9
    RNG.previous()
    return dict(model=get_model9(Mish, norm=nn.BatchNorm2d), base_lr=1e-2, leaky=0.0003) | kw

# %% ../../nbs/contest/other_arch/resnet18d_old_first_attempt.ipynb 21
# The last resnet model 92.8% 5epochs
def model_base_resnet():
    from miniai.resnet import get_model
    RNG.previous()
    return dict(model=get_model(act_gr, norm=nn.BatchNorm2d))

# %% ../../nbs/contest/other_arch/resnet18d_old_first_attempt.ipynb 43
class OneCycleLRWithPlateau(lr_scheduler.OneCycleLR):
    def __init__(self, *args, pct_start=0.1, pct_plateau=0.2, **kwargs):
        kwargs["pct_start"] = pct_start
        super(OneCycleLRWithPlateau, self).__init__(*args, **kwargs)
        self._schedule_phases = [
            {
                'end_step': float(pct_start * self.total_steps) - 1,
                'start_lr': 'initial_lr',
                'end_lr': 'max_lr',
                'start_momentum': 'max_momentum',
                'end_momentum': 'base_momentum',
            },
            {
                'end_step': float((pct_start + pct_plateau) * self.total_steps) - 2,
                'start_lr': 'max_lr',
                'end_lr': 'max_lr',
                'start_momentum': 'base_momentum',
                'end_momentum': 'base_momentum',
            },
            {
                'end_step': self.total_steps - 1,
                'start_lr': 'max_lr',
                'end_lr': 'initial_lr',
                'start_momentum': 'base_momentum',
                'end_momentum': 'max_momentum',
            },
        ]

# %% ../../nbs/contest/other_arch/resnet18d_old_first_attempt.ipynb 49
from ..mixup import MixUpCB
class MixUpFP16CB(MixUpCB, AccelerateCB): pass

# %% ../../nbs/contest/other_arch/resnet18d_old_first_attempt.ipynb 55
def tfm_batch(b, tfm_x=fc.noop, tfm_y = fc.noop): return tfm_x(b[0]),tfm_y(b[1])
def get_augcb(*ag):
    tfms = nn.Sequential(*ag)
    return BatchTransformCB(partial(tfm_batch, tfm_x=tfms), on_val=False)
