# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/contest/resnet18d_lion.ipynb.

# %% auto 0
__all__ = ['dadapt_adam', 'adamw', 'mixup', 'save_model']

# %% ../../nbs/contest/resnet18d_lion.ipynb 3
import pickle,gzip,math,os,time,shutil,torch,random
import fastcore.all as fc,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt
from collections.abc import Mapping
from pathlib import Path
from operator import attrgetter,itemgetter
from functools import partial
from copy import copy
from contextlib import contextmanager

import torchvision.transforms.functional as TF,torch.nn.functional as F
from torchvision import transforms
from torch import tensor,nn,optim
from torch.utils.data import DataLoader,default_collate
from torch.nn import init
from torch.optim import lr_scheduler
from torcheval.metrics import MulticlassAccuracy
from datasets import load_dataset,load_dataset_builder

from ..datasets import *
from ..conv import *
from ..learner import *
from ..activations import *
from ..init import *
from ..sgd import *
from ..resnet import *
from ..augment import *
from .ct94ep5 import *
from ..utils import *
from ..accel import *
import timm
from .base import *

# %% ../../nbs/contest/resnet18d_lion.ipynb 10
import dadaptation
def dadapt_adam():return dict(opt_func=partial(dadaptation.DAdaptAdam, weight_decay=0.0), base_lr=1,)

# %% ../../nbs/contest/resnet18d_lion.ipynb 11
def adamw(lr=1e-2, wd=0.01, **kw): return dict(opt_func=partial(optim.AdamW, weight_decay=wd), base_lr=1e-2, **kw)

# %% ../../nbs/contest/resnet18d_lion.ipynb 12
def mixup(alpha=0.4,lbl_smooth=0.1, **kw): return dict(train_cb=MixUpFP16CB(alpha=alpha,use_prev=True,label_smoothing=lbl_smooth), **kw)

# %% ../../nbs/contest/resnet18d_lion.ipynb 19
def save_model(learn, name):
    from accelerate import Accelerator
    mdl_path = Path.home()/"models"/"fmnist"
    mdl_path.mkdir(parents=True,exist_ok=True)
    model=learn.cbs[-1].acc.unwrap_model(learn.model)
    state_dict = model.state_dict()
    learn.cbs[-1].acc.save(state_dict,  mdl_path/name)
