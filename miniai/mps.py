# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/12_mps.ipynb.

# %% auto 0
__all__ = ['init_weights', 'ReseedCB']

# %% ../nbs/12_mps.ipynb 2
import torch, os
import torch.backends.mps # for pyright
import fastcore.all as fc
# [W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel 
# work has started or after set_num_threads call when using native parallel backend (function set_num_threads)
# Alternative if we won't find a way to use mutliprocessing with MPS:
if torch.backends.mps.is_available():
    if (k:='OMP_NUM_THREADS') not in os.environ: os.environ[k]='1'
    if (k:='PYTORCH_ENABLE_MPS_FALLBACK') not in os.environ: os.environ[k]='1'

# %% ../nbs/12_mps.ipynb 3
from .init import init_weights as orig_init_weights
from .activations import set_seed
from .learner import Callback


# %% ../nbs/12_mps.ipynb 8
def init_weights(m, *args, **kwargs):
    devs = [p.device for p in m.parameters()]
    try:
        m.to('cpu')
        return orig_init_weights(m, *args, **kwargs)
    finally:
        for p,d in zip(m.parameters(), devs): m.to(d)

# This if cannot be in front of init_weights as then it nbdev won't put it to __all__
if not torch.backends.mps.is_available(): init_weights = orig_init_weights # type: ignore 

# %% ../nbs/12_mps.ipynb 11
class ReseedCB(Callback):
    order = 0
    def __init__(self): self.gen, self.new_seed = torch.Generator(), None
    def before_fit(self, learn): 
        self.set_seed(self.new_seed)
        print('Using seed', self.new_seed)
    def set_seed(self, seed=None): 
        if seed is None: 
            self.new_seed = torch.randint(2**31, [1], generator=self.gen).item()
            print(f"New seed: {self.new_seed}")
        else:
            self.new_seed = seed
        set_seed(self.new_seed)
        return self.new_seed
    def previous(self): self.set_seed(self.new_seed)
    def new(self): self.set_seed()
