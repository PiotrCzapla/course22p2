# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/11_initializing_lsuv.ipynb.

# %% auto 0
__all__ = ['zero_bias', 'lsuv_init', 'lsuv_layers', 'LSUVInit', 'svd_orthonormal', 'orthogonal_init_paper', 'orthogonal_init']

# %% ../nbs/11_initializing_lsuv.ipynb 3
import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt
import sys,gc,traceback
import fastcore.all as fc
from collections.abc import Mapping
from pathlib import Path
from operator import attrgetter,itemgetter
from functools import partial
from copy import copy
from contextlib import contextmanager

import torchvision.transforms.functional as TF,torch.nn.functional as F
from torch import tensor,nn,optim
from torch.utils.data import DataLoader,default_collate
from torch.nn import init
from torcheval.metrics import MulticlassAccuracy
from datasets import load_dataset,load_dataset_builder

from .datasets import *
from .conv import *
from .learner import *
from .activations import *

# %% ../nbs/11_initializing_lsuv.ipynb 23
def zero_bias(m):
    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.Linear)):
        try:
            nn.init.zero_(m.bias)
        except AttributeError: pass
    

# %% ../nbs/11_initializing_lsuv.ipynb 26
def _lsuv_stats(hook, mod, inp, outp):
    acts = to_cpu(outp)
    hook.mean = acts.mean()
    hook.std = acts.std()

@no_grad()
def lsuv_init(model, m_act, m_in, xb, eps=1e-3, log=print, max_step=10):
    h = Hook(m_act, _lsuv_stats)
    log(f'LSUV: {m_in} {m_act if m_act!=m_in else ""}')
    with torch.no_grad():
        while model(xb) is not None and (abs(h.std-1)>eps or abs(h.mean)>eps):
            log(f'LSUV: {h.mean} {h.std} {max_step}')
            if abs(h.mean) > eps: m_in.bias -= h.mean
            if abs(h.std-1) > eps: m_in.weight.data /= h.std
            max_step -= 1
            if max_step == 0: 
                break
        log(f'LSUV: {m_in} {h.mean} {h.std} {max_step}')
    h.remove()
    
def lsuv_layers(model):
    conv_lin = [o for o in model.modules() if isinstance(o, (nn.Conv2d, nn.Linear))]
    return zip(conv_lin, conv_lin)

class LSUVInit(Callback):
    def __init__(self, layers=None, eps=1e-3, verbose=False, cancel_fit=False, skip_last=0):
        """layers - a function that returns iterable of point of measurement and conv|linear to tweak"""
        self.layers = layers if layers is not None else lsuv_layers
        self.log = fc.noop if not verbose else print
        self.eps = eps
        self.cancel_fit = cancel_fit
        self.skip_last = -skip_last if skip_last != 0 else None
    
    def before_batch(self, learn):
        if getattr(learn.model, 'lsuv_init', False): return
        layers = list(self.layers(learn.model))
        xb, _ = learn.batch
        training = learn.model.training
        learn.model.train(False)
        for ms in layers[:self.skip_last]: 
            lsuv_init(learn.model, *ms, xb, eps=self.eps, log=self.log)
        learn.model.lsuv_init = True
        learn.model.train(training)
        print(f'LSUV init done on {len(layers)} layers')
        if self.cancel_fit: raise CancelFitException()


# %% ../nbs/11_initializing_lsuv.ipynb 34
# Orthonorm init code is taken from Lasagne
# https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py
def svd_orthonormal(shape):
    if len(shape) < 2:
        raise RuntimeError("Only shapes of length 2 or more are supported.")
    flat_shape = (shape[0], np.prod(shape[1:]))
    a = np.random.normal(0.0, 1.0, flat_shape)#w;
    u, _, v = np.linalg.svd(a, full_matrices=False)
    q = u if u.shape == flat_shape else v
    q = q.reshape(shape)
    return q.astype(np.float32)
# https://github.com/ducha-aiki/LSUV-pytorch  
def orthogonal_init_paper(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
        if hasattr(m, 'weight'):
            w_ortho = svd_orthonormal(m.weight.shape)
            m.weight.data = torch.from_numpy(w_ortho)
            try:
                nn.init.constant_(m.bias, 0)
            except:
                pass
    return


# %% ../nbs/11_initializing_lsuv.ipynb 42
def orthogonal_init(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
        if hasattr(m, 'weight'):
            nn.init.orthogonal_(m.weight)
            try: nn.init.constant_(m.bias, 0)
            except AttributeError: pass
